{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ejvBgokEuH-C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the dataset\n",
        "class SortingDataset(Dataset):\n",
        "    def __init__(self, sequence_length, dataset_size, number_range):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.dataset_size = dataset_size\n",
        "        self.number_range = number_range\n",
        "        self.data = self._generate_data()\n",
        "\n",
        "    def _generate_data(self):\n",
        "        data = np.random.randint(self.number_range[0], self.number_range[1], (self.dataset_size, self.sequence_length))\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        unsorted_sequence = self.data[idx]\n",
        "        sorted_sequence = np.sort(unsorted_sequence)\n",
        "        return torch.tensor(unsorted_sequence, dtype=torch.long), torch.tensor(sorted_sequence, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "vVVFLSqHuH-D"
      },
      "outputs": [],
      "source": [
        "sequence_length = 10\n",
        "dataset_size = 30000\n",
        "number_range = (1, 99)\n",
        "batch_size = 32\n",
        "\n",
        "dataset = SortingDataset(sequence_length, dataset_size, number_range)\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "CuFXor6buH-E",
        "outputId": "6fc10e3f-0ae6-4df1-efd6-20e941aaaf79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if CUDA is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, model_dim, num_heads, feedforward_dim, dropout=0.1):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(model_dim, num_heads, dropout=dropout)\n",
        "        self.linear1 = nn.Linear(model_dim, feedforward_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(feedforward_dim, model_dim)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(model_dim)\n",
        "        self.norm2 = nn.LayerNorm(model_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
        "        src2 = self.norm1(src)\n",
        "        src = src + self.dropout1(self.self_attn(src2, src2, src2, attn_mask=src_mask,\n",
        "                              key_padding_mask=src_key_padding_mask)[0])\n",
        "        src2 = self.norm2(src)\n",
        "        src = src + self.dropout2(self.linear2(self.dropout(self.activation(self.linear1(src2)))))\n",
        "        return src\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, layer, num_layers):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([copy.deepcopy(layer) for _ in range(num_layers)])\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def forward(self, src, mask=None, src_key_padding_mask=None):\n",
        "        output = src\n",
        "\n",
        "        for layer in self.layers:\n",
        "            output = layer(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "3P1S17gnuH-F"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Define the simplified GPT model\n",
        "class SimpleGPT(nn.Module):\n",
        "    def __init__(self, input_dim, model_dim, output_dim, num_heads, num_layers):\n",
        "        super(SimpleGPT, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, model_dim)\n",
        "        transformer_layer = TransformerEncoderLayer(model_dim=model_dim, num_heads=num_heads, feedforward_dim=model_dim*4)\n",
        "        self.transformer = TransformerEncoder(layer=transformer_layer, num_layers=num_layers)\n",
        "        self.output_layer = nn.Linear(model_dim, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x.mean(axis=1)\n",
        "\n",
        "\n",
        "# Define the custom loss function\n",
        "def custom_sorting_loss_function(outputs, targets):\n",
        "    #print(outputs.shape, targets.shape)\n",
        "    loss = torch.mean((outputs - targets) ** 2)\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "XE29DHlruH-F"
      },
      "outputs": [],
      "source": [
        "def train(model, data_loader, loss_fn, optimizer, epochs=1, device=None, threshold=1.1):\n",
        "    model.train()\n",
        "    exp_mean = None\n",
        "    exp_var = None\n",
        "    exp_std = None\n",
        "    for epoch in range(epochs):\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)  # Move data to the device\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            # Directly calculate the loss without reshaping\n",
        "            loss = loss_fn(outputs, targets.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        if exp_mean is None:\n",
        "            exp_mean = loss.item()\n",
        "        else:\n",
        "            exp_mean = (exp_mean + loss.item()) / 2\n",
        "            if exp_var is None:\n",
        "                exp_var = (loss.item() - exp_mean) ** 2\n",
        "            else:\n",
        "                exp_var = (exp_var + (loss.item() - exp_mean) ** 2) / 2\n",
        "            exp_std = exp_var ** 0.5\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {loss.item()}, Exponential mean: {exp_mean}, Expoential std: {exp_std}')\n",
        "        if exp_mean < threshold:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Uch-mw9buH-G"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Model and DataLoader setup\n",
        "input_dim = 101  # Plus one to accommodate the range\n",
        "model_dim = 128\n",
        "output_dim = 10  # This matches the sequence length\n",
        "num_heads = 4\n",
        "num_layers = 4\n",
        "\n",
        "model = SimpleGPT(input_dim=input_dim, model_dim=model_dim, output_dim=output_dim, num_heads=num_heads, num_layers=num_layers)\n",
        "model = model.to(device)  # Move model to the chosen device\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = custom_sorting_loss_function\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "GyUbu4h0uH-G",
        "outputId": "165ec06d-c0a3-48b4-f253-14b4ff0031f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 34.17226791381836, Exponential mean: 34.17226791381836, Expoential std: None\n",
            "Epoch 2, Loss: 44.27728271484375, Exponential mean: 39.224775314331055, Expoential std: 5.052507400512695\n",
            "Epoch 3, Loss: 37.39603042602539, Exponential mean: 38.31040287017822, Expoential std: 3.630696076433662\n",
            "Epoch 4, Loss: 41.59498977661133, Exponential mean: 39.952696323394775, Expoential std: 2.817719094046525\n",
            "Epoch 5, Loss: 46.94095993041992, Exponential mean: 43.44682812690735, Expoential std: 3.173995743008519\n",
            "Epoch 6, Loss: 34.64754867553711, Exponential mean: 39.04718840122223, Expoential std: 3.8360838554744103\n",
            "Epoch 7, Loss: 32.84743118286133, Exponential mean: 35.94730979204178, Expoential std: 3.487462310755913\n",
            "Epoch 8, Loss: 22.764333724975586, Exponential mean: 29.355821758508682, Expoential std: 5.273049775279624\n",
            "Epoch 9, Loss: 26.11663246154785, Exponential mean: 27.736227110028267, Expoential std: 3.9005218085509332\n",
            "Epoch 10, Loss: 46.28580856323242, Exponential mean: 37.011017836630344, Expoential std: 7.114626251646861\n",
            "Epoch 11, Loss: 26.792490005493164, Exponential mean: 31.901753921061754, Expoential std: 6.193645310298046\n",
            "Epoch 12, Loss: 57.048805236816406, Exponential mean: 44.47527957893908, Expoential std: 9.910973456201878\n",
            "Epoch 13, Loss: 28.975387573242188, Exponential mean: 36.725333576090634, Expoential std: 8.896321090670144\n",
            "Epoch 14, Loss: 36.37425231933594, Exponential mean: 36.549792947713286, Expoential std: 6.291873467438514\n",
            "Epoch 15, Loss: 40.08755111694336, Exponential mean: 38.31867203232832, Expoential std: 4.62150435173685\n",
            "Epoch 16, Loss: 35.09360885620117, Exponential mean: 36.70614044426475, Expoential std: 3.461109691675885\n",
            "Epoch 17, Loss: 36.42068862915039, Exponential mean: 36.56341453670757, Expoential std: 2.449454121074812\n",
            "Epoch 18, Loss: 44.84332275390625, Exponential mean: 40.70336864530691, Expoential std: 3.4014001170517223\n",
            "Epoch 19, Loss: 35.44867706298828, Exponential mean: 38.076022854147595, Expoential std: 3.0391173605672117\n",
            "Epoch 20, Loss: 42.941932678222656, Exponential mean: 40.508977766185126, Expoential std: 2.752771688254273\n",
            "Epoch 21, Loss: 29.440046310424805, Exponential mean: 34.974512038304965, Expoential std: 4.37081587696933\n",
            "Epoch 22, Loss: 48.156490325927734, Exponential mean: 41.56550118211635, Expoential std: 5.59218961249557\n",
            "Epoch 23, Loss: 33.874107360839844, Exponential mean: 37.7198042714781, Expoential std: 4.799060813877855\n",
            "Epoch 24, Loss: 40.93397903442383, Exponential mean: 39.32689165295096, Expoential std: 3.5786669687879096\n",
            "Epoch 25, Loss: 38.580650329589844, Exponential mean: 38.9537709912704, Expoential std: 2.5442166084736755\n",
            "Epoch 26, Loss: 35.6524772644043, Exponential mean: 37.30312412783735, Expoential std: 2.1444898249460955\n",
            "Epoch 27, Loss: 39.26202392578125, Exponential mean: 38.2825740268093, Expoential std: 1.6670570946871464\n",
            "Epoch 28, Loss: 37.2216796875, Exponential mean: 37.75212685715465, Expoential std: 1.2370233540118347\n",
            "Epoch 29, Loss: 42.23453903198242, Exponential mean: 39.993332944568536, Expoential std: 1.810142467408539\n",
            "Epoch 30, Loss: 39.3827018737793, Exponential mean: 39.688017409173916, Expoential std: 1.2980433984403559\n",
            "Epoch 31, Loss: 61.26108932495117, Exponential mean: 50.47455336706254, Expoential std: 7.682261211227428\n",
            "Epoch 32, Loss: 35.71255111694336, Exponential mean: 43.09355224200295, Expoential std: 7.533137292179814\n",
            "Epoch 33, Loss: 29.725540161132812, Exponential mean: 36.40954620156788, Expoential std: 7.121239155210372\n",
            "Epoch 34, Loss: 38.80068588256836, Exponential mean: 37.60511604206812, Expoential std: 5.105949194283816\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Train the model\n",
        "train(model, data_loader, loss_fn, optimizer, epochs=50, device=device, threshold=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "oLfdXkVAuH-H",
        "outputId": "6d89b3af-033f-4b04-cac6-e04081b91ef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Input Sequence  True Sorted Sequence  Predicted Sort\n",
            "0              61                     5        4.982429\n",
            "1              74                    41       42.578876\n",
            "2              53                    53       53.088623\n",
            "3               5                    53       53.528297\n",
            "4              41                    60       60.225136\n",
            "5              81                    61       60.768818\n",
            "6              53                    70       71.054192\n",
            "7              70                    74       74.110855\n",
            "8              60                    81       81.078911\n",
            "9              92                    92       92.710854\n"
          ]
        }
      ],
      "source": [
        "# Demonstrate sorting with the trained model\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def demonstrate_sorting(model, number_range, sequence_length):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_sequence = torch.randint(number_range[0], number_range[1], (sequence_length,))\n",
        "        input_sequence = input_sequence.to(device)\n",
        "        sorted_sequence = torch.sort(input_sequence).values\n",
        "        output = model(input_sequence.unsqueeze(0))\n",
        "        predicted_sort = output.squeeze(0).cpu()  # Move data back to CPU for printing\n",
        "\n",
        "        demo_df = pd.DataFrame({\n",
        "            'Input Sequence': input_sequence.cpu().numpy(),\n",
        "            'True Sorted Sequence': sorted_sequence.cpu().numpy(),\n",
        "            'Predicted Sort': predicted_sort.cpu().numpy()\n",
        "        })\n",
        "        print(demo_df)\n",
        "\n",
        "\n",
        "\n",
        "demonstrate_sorting(model, number_range, sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcbaB4f-uH-H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot9dIC7luH-I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNFeTCA8uH-I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hASDHqXJuH-I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSKaaJHIuH-I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
